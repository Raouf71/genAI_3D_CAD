{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e8db8ac2-5221-44de-a53e-cb5ab37ac8f5",
      "metadata": {
        "id": "e8db8ac2-5221-44de-a53e-cb5ab37ac8f5"
      },
      "source": [
        "### Setup (Installs, Data, Models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989d1cb5-5464-4d9d-ac1e-6e16276d3698",
      "metadata": {
        "id": "989d1cb5-5464-4d9d-ac1e-6e16276d3698"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index\n",
        "%pip install llama-index-core==0.10.42\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install llama-index-postprocessor-flag-embedding-reranker\n",
        "%pip install git+https://github.com/FlagOpen/FlagEmbedding.git\n",
        "%pip install llama-index-graph-stores-neo4j\n",
        "%pip install llama-cloud-services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580ecfc2-b082-4c4e-910a-7f88e8137aad",
      "metadata": {
        "id": "580ecfc2-b082-4c4e-910a-7f88e8137aad"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import os\n",
        "\n",
        "# API access to llama-cloud\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-WROpF69GBXDRmw9jP8oiN1lwU6iDTbJs0kRY0nj3ReVfXtuY\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f683f2-a41e-4975-843c-435407132f0e",
      "metadata": {
        "id": "d6f683f2-a41e-4975-843c-435407132f0e"
      },
      "source": [
        "\n",
        "_______________________________\n",
        "### Setup Model\n",
        "Here we use gpt-4o and default OpenAI embeddings.\n",
        "_______________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91854ee-d57a-4d7b-bcc8-c6bd7214fe84",
      "metadata": {
        "id": "d91854ee-d57a-4d7b-bcc8-c6bd7214fe84"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o\")\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Best chunk-configuration (https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5)\n",
        "Settings.chunk_size = 1024\n",
        "Settings.chunk_overlap = 200\n",
        "print(Settings.context_window)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf33f7-b195-444d-9355-ab47c91be6ad",
      "metadata": {
        "id": "5bcf33f7-b195-444d-9355-ab47c91be6ad"
      },
      "source": [
        "_______________________________\n",
        "### Load and parse Data with agent\n",
        "_______________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d13f0b-1749-4c06-a4f7-b6f885db04d3",
      "metadata": {
        "id": "96d13f0b-1749-4c06-a4f7-b6f885db04d3",
        "outputId": "c237037a-d192-49bb-a2a6-5b5184b403b3"
      },
      "outputs": [],
      "source": [
        "# Better parsing\n",
        "from llama_cloud_services import LlamaParse\n",
        "\n",
        "docs = LlamaParse(\n",
        "    parse_mode=\"parse_page_with_agent\",\n",
        "    # model=\"openai-gpt-4-1-mini\",\n",
        "    model=\"anthropic-sonnet-4.0\",\n",
        "    high_res_ocr=True,\n",
        "    adaptive_long_table=True,\n",
        "    outlined_table_extraction=True,\n",
        "    output_tables_as_HTML=True,\n",
        ").load_data(\"../data/lager.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d9c8d9f",
      "metadata": {},
      "source": [
        "_______________________________\n",
        "### Split docs into pages\n",
        "_______________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9afcf38e-3c7e-4b48-ae23-61b33f1a448a",
      "metadata": {
        "id": "9afcf38e-3c7e-4b48-ae23-61b33f1a448a"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from llama_index.core.schema import TextNode, Document\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "\n",
        "def get_sub_docs(docs):\n",
        "    \"\"\"Split docs into pages, by separator.\"\"\"\n",
        "    sub_docs = []\n",
        "    for doc in docs:\n",
        "        doc_chunks = doc.text.split(\"\\n---\\n\")\n",
        "        for doc_chunk in doc_chunks:\n",
        "            sub_doc = Document(\n",
        "                text=doc_chunk,\n",
        "                metadata=deepcopy(doc.metadata),\n",
        "            )\n",
        "            sub_docs.append(sub_doc)\n",
        "\n",
        "    return sub_docs\n",
        "\n",
        "# this will split into pages\n",
        "sub_docs = get_sub_docs(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e55bcae5-43ba-4363-9109-d8080d19ce5a",
      "metadata": {
        "id": "e55bcae5-43ba-4363-9109-d8080d19ce5a"
      },
      "source": [
        "_______________________________\n",
        "### Initialize Graph Store\n",
        "Here we use Neo4j but you can also use our other integrations like Nebula\n",
        "_______________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b86a0e7b-bc15-45ed-b1f7-b4c82d16b815",
      "metadata": {
        "id": "b86a0e7b-bc15-45ed-b1f7-b4c82d16b815"
      },
      "source": [
        "To launch Neo4j locally, first ensure you have docker installed. Then, you can launch the database with the following docker command\n",
        "\n",
        "```bash\n",
        "docker run \\\n",
        "    -p 7474:7474 -p 7687:7687 \\\n",
        "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n",
        "    --name neo4j-apoc \\\n",
        "    -e NEO4J_apoc_export_file_enabled=true \\\n",
        "    -e NEO4J_apoc_import_file_enabled=true \\\n",
        "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
        "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n",
        "    neo4j:latest\n",
        "```\n",
        "\n",
        "From here, you can open the db at [http://localhost:7474/](http://localhost:7474/). On this page, you will be asked to sign in. Use the default username/password of `neo4j` and `neo4j`.\n",
        "\n",
        "Once you login for the first time, you will be asked to change the password.\n",
        "\n",
        "After this, you are ready to create your first property graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25ed865-b78e-4856-9473-7123d9924d46",
      "metadata": {
        "id": "e25ed865-b78e-4856-9473-7123d9924d46"
      },
      "outputs": [],
      "source": [
        "from llama_index.graph_stores.neo4j import Neo4jPGStore\n",
        "\n",
        "graph_store = Neo4jPGStore(\n",
        "    username=\"neo4j\",\n",
        "    password=\"graph1312\",\n",
        "    url=\"bolt://localhost:7687\",\n",
        ")\n",
        "vec_store = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10723825-328f-4175-ad85-637b0c28262c",
      "metadata": {
        "id": "10723825-328f-4175-ad85-637b0c28262c"
      },
      "source": [
        "_______________________________\n",
        "### Construct Knowledge Graph, Get Retrievers\n",
        "This section shows you how to construct the knowledge graph over the existing documents.\n",
        "_______________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a598cd51",
      "metadata": {},
      "source": [
        "#### Document indexing + Extraction (entities/relations)\n",
        "**Note**: we have the default extractors (implicit path, simple llm path) configured. You can also choose to use a pre-defined schema as mentioned in this [notebook](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/property_graph/property_graph_advanced.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b3d81c4-95a8-409b-a448-ac18e193effc",
      "metadata": {
        "id": "6b3d81c4-95a8-409b-a448-ac18e193effc"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.indices.property_graph import (\n",
        "    ImplicitPathExtractor,\n",
        "    SimpleLLMPathExtractor,\n",
        ")\n",
        "from llama_index.core import PropertyGraphIndex\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "index = PropertyGraphIndex.from_documents(\n",
        "    sub_docs,\n",
        "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
        "    kg_extractors=[\n",
        "        ImplicitPathExtractor(),\n",
        "        SimpleLLMPathExtractor(\n",
        "            llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3),\n",
        "            num_workers=4,\n",
        "            max_paths_per_chunk=10,\n",
        "        ),\n",
        "    ],\n",
        "    property_graph_store=graph_store,\n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc67771a",
      "metadata": {},
      "source": [
        "#### Neo4j\n",
        "To see the entire graph -> run cypher command ```match n=() return n``` <br>\n",
        "To delete the entire graph -> run cypher command ```match n=() detach delete n```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c1f0f65-2d15-471c-9e74-6cebcecee1f4",
      "metadata": {
        "id": "0c1f0f65-2d15-471c-9e74-6cebcecee1f4"
      },
      "source": [
        "_______________________________\n",
        "### Retrieval\n",
        "_______________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e0867c1-dd3d-4e84-93a3-30b4ec861024",
      "metadata": {
        "id": "1e0867c1-dd3d-4e84-93a3-30b4ec861024"
      },
      "source": [
        "#### Run baseline vector search\n",
        "\n",
        "We also build a \"baseline\" vector index. This follows the \"naive\" RAG pipeline approach of chunking and vector embedding. We use this as a comparison point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "255e4f1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "base_index = VectorStoreIndex.from_documents(sub_docs, embed_model=embed_model)\n",
        "vector_retriever = base_index.as_retriever(similarity_top_k=10)\n",
        "base_query_engine = RetrieverQueryEngine(vector_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a496a3b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "response = base_query_engine.query(\n",
        "    \"Worum geht es in dem Dokument? Antworte in 2-3 Sätzen.\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bbb21a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "response = base_query_engine.query(\n",
        "    \"Wie ist die Seitenwirkung von dem Axialrillenkugellager?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "572a41b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "response = base_query_engine.query(\n",
        "    \"Was bedeutet 'Das Axialrillenkugellager ist einseitig wirkend'? Antworte knapp basierend auf technische Quellen.\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0355adb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "response = base_query_engine.query(\n",
        "    \"Welches DIN-Bezeichnungen (und Lagerreihen falls vorhanden) sind im Dokument zu finden? Kurz auflisten bitte.\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c72a78f",
      "metadata": {},
      "outputs": [],
      "source": [
        "response = base_query_engine.query(\n",
        "    \"Was bedeutet 'Lagerreihe 62'? Kurz.\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fbd5db3",
      "metadata": {},
      "source": [
        "### Test results \n",
        "\n",
        "✅ Succeeded all tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e6acc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# positive test case\n",
        "response = base_query_engine.query(\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=55\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73a33a2a",
      "metadata": {},
      "source": [
        "### Test results \n",
        "\n",
        "✅ Succeeded positive test case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1c2a09",
      "metadata": {},
      "outputs": [],
      "source": [
        "# negative test case\n",
        "response = base_query_engine.query(\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=15\"\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=20\"\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=85\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3b17b5e",
      "metadata": {},
      "source": [
        "### Test results \n",
        "\n",
        "✅ Succeeded test case '...mit d=15' <br>\n",
        "✅ Succeeded test case '...mit d=20' <br>\n",
        "❌ Failed test case '...mit d=85'\n",
        "-> Pipeline confused small 'd' with 'D'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e668ac4",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(response.source_nodes))\n",
        "for node in response.source_nodes:\n",
        "    print(\"---\")\n",
        "    print(node.get_content())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfabc20e-bc8b-4e80-80ef-cfdee07a6e10",
      "metadata": {
        "id": "cfabc20e-bc8b-4e80-80ef-cfdee07a6e10"
      },
      "source": [
        "#### Run KG search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4869e97",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.indices.property_graph import VectorContextRetriever\n",
        "\n",
        "kg_retriever = VectorContextRetriever(\n",
        "    index.property_graph_store,\n",
        "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
        "    similarity_top_k=7,\n",
        "    path_depth=1,\n",
        "    # include_text=False,\n",
        "    include_text=True,\n",
        ")\n",
        "\n",
        "nodes = kg_retriever.retrieve(\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=55\"\n",
        ")\n",
        "# nodes = kg_retriever.retrieve('san francisco')\n",
        "print(len(nodes))\n",
        "for idx, node in enumerate(nodes):\n",
        "    print(f\">> IDX: {idx}, {node.get_content()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f22515c",
      "metadata": {},
      "source": [
        "### Run both vector and KG search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea75c09f-a0d1-48fe-b349-5e52ffe4df03",
      "metadata": {
        "id": "ea75c09f-a0d1-48fe-b349-5e52ffe4df03"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.retrievers import BaseRetriever\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class CustomRetriever(BaseRetriever):\n",
        "    \"\"\"Custom retriever that performs both KG vector search and direct vector search.\"\"\"\n",
        "\n",
        "    def __init__(self, kg_retriever, vector_retriever):\n",
        "        self._kg_retriever = kg_retriever\n",
        "        self._vector_retriever = vector_retriever\n",
        "\n",
        "    def _retrieve(self, query_bundle) -> List[NodeWithScore]:\n",
        "        \"\"\"Retrieve nodes given query.\"\"\"\n",
        "        kg_nodes = self._kg_retriever.retrieve(query_bundle)\n",
        "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
        "\n",
        "        unique_nodes = {n.node_id: n for n in kg_nodes}\n",
        "        unique_nodes.update({n.node_id: n for n in vector_nodes})\n",
        "        return list(unique_nodes.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3dae1e1-b3a3-4896-91e5-1de95ed32a0d",
      "metadata": {
        "id": "b3dae1e1-b3a3-4896-91e5-1de95ed32a0d"
      },
      "outputs": [],
      "source": [
        "custom_retriever = CustomRetriever(kg_retriever, vector_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c71c51-32a5-4420-917c-6d42b33c2c64",
      "metadata": {
        "id": "c6c71c51-32a5-4420-917c-6d42b33c2c64"
      },
      "outputs": [],
      "source": [
        "nodes = custom_retriever.retrieve(\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=55\"\n",
        ")\n",
        "print(len(nodes))\n",
        "for idx, node in enumerate(nodes):\n",
        "    print(f\">> IDX: {idx}, {node.get_content()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "389f6d0c-12b2-45e3-916a-f521befd6b91",
      "metadata": {
        "id": "389f6d0c-12b2-45e3-916a-f521befd6b91"
      },
      "source": [
        "## Build Agent\n",
        "\n",
        "Now that we have the retriever, we can treat it as a RAG pipeline tool, and wrap it with an agent that can perform basic CoT reasoning and maintain conversation memory over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7e7854-5d4e-49b8-baaa-8ad1cba053a0",
      "metadata": {
        "id": "3f7e7854-5d4e-49b8-baaa-8ad1cba053a0"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "kg_query_engine = RetrieverQueryEngine(custom_retriever)\n",
        "kg_query_tool = QueryEngineTool(\n",
        "    query_engine=kg_query_engine,\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"query_tool\",\n",
        "        description=\"Provides information about row table lookups\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec7e8a74-2e9a-4e20-91a7-d997160af829",
      "metadata": {
        "id": "ec7e8a74-2e9a-4e20-91a7-d997160af829"
      },
      "outputs": [],
      "source": [
        "# from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent.workflow import ReActAgent\n",
        "from llama_index.core.workflow import Context\n",
        "\n",
        "agent = ReActAgent(\n",
        "    tools=[kg_query_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    allow_parallel_tool_calls=False,\n",
        ")\n",
        "\n",
        "# context to hold this session/state\n",
        "ctx = Context(agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d567f1e8-621d-4107-9e8f-75051c900ff3",
      "metadata": {
        "id": "d567f1e8-621d-4107-9e8f-75051c900ff3"
      },
      "source": [
        "## Try out Queries\n",
        "\n",
        "Now that the agent is setup, let's try out some queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d6060bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "handler = agent.run(\n",
        "    \"Welche Lagerrtypen haben ein Lager mit d=20?\",\n",
        "    ctx=ctx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ebffb9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9579d85c",
      "metadata": {},
      "outputs": [],
      "source": [
        "handler = agent.run(\n",
        "    \"Welche Lagerrtypen haben ein Lager mit d=15?\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63075826",
      "metadata": {},
      "source": [
        "### Test results \n",
        "\n",
        "✅ Succeeded postive test case '...mit d=20' <br>\n",
        "✅ Succeeded negative test case '...mit d=15' <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d0c63e-817f-4615-a237-82d728917e4e",
      "metadata": {
        "id": "f1d0c63e-817f-4615-a237-82d728917e4e",
        "outputId": "d2762cff-199a-4a0a-8167-c1e4013a6889"
      },
      "outputs": [],
      "source": [
        "# positive test case\n",
        "handler = agent.run(\n",
        "    \"Listen Sie mir bitte die komplette Reihe für den Axialrillenkugellager DIN 711 wo d_w=30\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa005645",
      "metadata": {},
      "source": [
        "### Test results \n",
        "\n",
        "✅ Succeeded test partially: <br>\n",
        "    - detected d_w correctly <br>\n",
        "    - forgot to mention d_g for that row (Parsing could be struggling with subscripts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b9c2fc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# positive test case\n",
        "handler = agent.run(\n",
        "    \"Listen Sie mir bitte die komplette(n) Reihe(n) für den Kegelrollenlager DIN 720 wo ri_min=1.5\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a993c61e",
      "metadata": {},
      "source": [
        "### Test results \n",
        "\n",
        "❌ Failed: Should have generated rows from 30207, 30208, 30209 abd 30210 only. <br>\n",
        "Cause: Parsing could be struggling with subscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41f0c74",
      "metadata": {},
      "outputs": [],
      "source": [
        "# negative test case\n",
        "handler = agent.run(\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=15\"\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=20\"\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=85\",\n",
        "    ctx=ctx)\n",
        "\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26868b5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# memory test 1\n",
        "handler = agent.run(\n",
        "    \"I deleted our conversation by mistake, what was my last question about? answer briefly\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81881133",
      "metadata": {},
      "outputs": [],
      "source": [
        "# memory test 2\n",
        "handler = agent.run(\n",
        "    \"And what was your answer to my last question? answer briefly\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7fe98f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# image test 2\n",
        "handler = agent.run(\n",
        "    \"Can you briefly describe the figure of the 'Kegelrollenlager DIN 720' in 2-3 sentences in German?\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97f64b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# positive test case\n",
        "handler = agent.run(\n",
        "    \"Listen Sie mir bitte die komplette(n) Reihe(n) für den Kegelrollenlager DIN 720 wo ri_min=1.5\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2183283a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# negative test case\n",
        "handler = agent.run(\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=15\"\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=20\"\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=85\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa01d83",
      "metadata": {},
      "source": [
        "#### slightly better user prompt (not system prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5b161c",
      "metadata": {},
      "outputs": [],
      "source": [
        "handler = agent.run(\n",
        "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 und Lagerreihe NU2 mit d=85. Achtung; Tabellenkopf 'd' and 'D' sind nicht gleich.\",\n",
        "    ctx=ctx)\n",
        "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n",
        "\n",
        "async for ev in handler.stream_events():\n",
        "    # if isinstance(ev, ToolCallResult):\n",
        "    #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
        "    if isinstance(ev, AgentStream):\n",
        "        print(f\"{ev.delta}\", end=\"\", flush=True)\n",
        "\n",
        "response = await handler"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kg-neo4j (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
