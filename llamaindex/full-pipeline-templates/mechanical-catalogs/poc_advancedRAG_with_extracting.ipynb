{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1f7051",
   "metadata": {},
   "source": [
    "## PoC for advanced RAG patterns (naive RAG, hybrid RAG, GraphRAG) with **extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7602e0",
   "metadata": {},
   "source": [
    "### Activate python virtual env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1be787",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%source ../llamaindex-venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02000905",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Import libraries/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Parse\n",
    "from llama_cloud_services import LlamaParse\n",
    "from copy import deepcopy\n",
    "\n",
    "# Modeös\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# vector index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# kg index\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import VectorContextRetriever\n",
    "\n",
    "# Extractors\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    ImplicitPathExtractor,\n",
    "    SimpleLLMPathExtractor,\n",
    ")\n",
    "\n",
    "# Custom retriever\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import NodeWithScore, Document\n",
    "from typing import List\n",
    "\n",
    "# Retrievers\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import BM25Retriever\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.graph_stores.neo4j import Neo4jPGStore\n",
    "\n",
    "# agent\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "# from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent.workflow import ReActAgent\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d2e5d",
   "metadata": {},
   "source": [
    "### Load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303748ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# API access to llama-cloud + openAI\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943b7a8",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### Setup Models\n",
    "Here we use gpt-4o and default OpenAI embeddings.\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = OpenAI(model=\"gpt-4o\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "#Settings.llm = llm\n",
    "#Settings.embed_model = embed_model\n",
    "\n",
    "# Best chunk-configuration \n",
    "Settings.chunk_size = 1024\n",
    "Settings.chunk_overlap = 200\n",
    "print(Settings.context_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df9231",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 1. Parsing\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae61b60",
   "metadata": {},
   "source": [
    "##### Load and parse Data with agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = LlamaParse(\n",
    "    parse_mode=\"parse_page_with_agent\",\n",
    "    # model=\"openai-gpt-4-1-mini\",\n",
    "    model=\"anthropic-sonnet-4.0\",\n",
    "    high_res_ocr=True,\n",
    "    adaptive_long_table=True,\n",
    "    outlined_table_extraction=True,\n",
    "    output_tables_as_HTML=True,\n",
    ").load_data(\"../data/lager.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30997cf",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 2. Splitting\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a187dca",
   "metadata": {},
   "source": [
    "\n",
    "##### 2.1 Metadata normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(docs):\n",
    "    md = dict(d.metadata or {})\n",
    "\n",
    "    # Stable source identifiers for citations/debugging\n",
    "    md[\"source_path\"] = str(pdf_path)\n",
    "    md[\"source_file\"] = pdf_path.name\n",
    "    md[\"source_id\"] = f\"{pdf_path.stem}\"          # stable doc id\n",
    "    md[\"doc_type\"] = \"pdf\"\n",
    "\n",
    "    # Page-level fields (best-effort)\n",
    "    # If LlamaParse already provides a page number, keep it; otherwise fallback\n",
    "    page = md.get(\"page_number\") or md.get(\"page\") or (i + 1)\n",
    "    md[\"page_number\"] = int(page)\n",
    "\n",
    "    d.metadata = md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971b766",
   "metadata": {},
   "source": [
    "\n",
    "##### 2.2 Split by page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_docs(docs):\n",
    "    sub_docs = []\n",
    "    for doc in docs:\n",
    "        page_chunks = doc.text.split(\"\\n---\\n\")\n",
    "        for i, chunk in enumerate(page_chunks):\n",
    "            md = deepcopy(doc.metadata)\n",
    "\n",
    "            # ensure page_number stays correct at page level\n",
    "            md[\"page_number\"] = md.get(\"page_number\", i + 1)\n",
    "\n",
    "            sub_docs.append(\n",
    "                Document(\n",
    "                    text=chunk,\n",
    "                    metadata=md,\n",
    "                )\n",
    "            )\n",
    "    return sub_docs\n",
    "\n",
    "sub_docs = get_sub_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ceab9",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 3. Extracting\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008eb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f9a6a",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 4. Indexing\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6fed6",
   "metadata": {},
   "source": [
    "##### 4.1 Vector-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index = VectorStoreIndex.from_documents(\n",
    "    sub_docs, \n",
    "    embed_model=embed_model,\n",
    "    # vector_store='',  # if not specified, embeddings live in RAM\n",
    "    # vector_store=faiss_store,  # or Pinecone / Weaviate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6628cc8",
   "metadata": {},
   "source": [
    "##### 4.2 KG-based (Init Graph-Store + Extract entities/relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000da0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = Neo4jPGStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"graph1312\",\n",
    "    url=\"bolt://localhost:7687\",\n",
    ")\n",
    "vec_store = None\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    sub_docs,\n",
    "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    "    kg_extractors=[\n",
    "        ImplicitPathExtractor(),\n",
    "        SimpleLLMPathExtractor(\n",
    "            llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3),\n",
    "            num_workers=4,\n",
    "            max_paths_per_chunk=10,\n",
    "        ),\n",
    "    ],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    "    # vector_store=vector_store,\n",
    "    # embed_kg_nodes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265243c5",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 5. Retrieval\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c481113",
   "metadata": {},
   "source": [
    "##### 5.1 Vector retriever (embeddings similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bcccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = base_index.as_retriever(similarity_top_k=10)\n",
    "naive_query_engine = RetrieverQueryEngine(vector_retriever)\n",
    "\n",
    "# Query\n",
    "response = naive_query_engine.query(\n",
    "    \"Worum geht es in dem Dokument? Antworte in 2-3 Sätzen.\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e9cb7",
   "metadata": {},
   "source": [
    "##### 5.2 Hybrid retriever (BM25 keyword + vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd495df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Retriever.from_documents(\n",
    "    sub_docs,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "hybrid_retriever = QueryFusionRetriever(\n",
    "    retrievers=[bm25, vector_retriever],\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "hybrid_query_engine = RetrieverQueryEngine.from_args(retriever=hybrid_retriever)\n",
    "\n",
    "# Query\n",
    "response = hybrid_query_engine.query(\n",
    "    \"Worum geht es in dem Dokument? Antworte in 2-3 Sätzen.\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95611e7f",
   "metadata": {},
   "source": [
    "##### 5.3 Knowledge graph retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_retriever = VectorContextRetriever(\n",
    "    index.property_graph_store,\n",
    "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    "    similarity_top_k=5,\n",
    "    path_depth=1,\n",
    "    # include_text=False,\n",
    "    include_text=True,\n",
    ")\n",
    "\n",
    "nodes = kg_retriever.retrieve(\n",
    "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=55\"\n",
    ")\n",
    "\n",
    "print(len(nodes))\n",
    "for idx, node in enumerate(nodes):\n",
    "    print(f\">> IDX: {idx}, {node.get_content()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbd7cf",
   "metadata": {},
   "source": [
    "#### 5.4 Custom retriever (vector+KG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever that performs both KG vector search and direct vector search.\"\"\"\n",
    "\n",
    "    def __init__(self, kg_retriever, vector_retriever):\n",
    "        self._kg_retriever = kg_retriever\n",
    "        self._vector_retriever = vector_retriever\n",
    "\n",
    "    def _retrieve(self, query_bundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "        kg_nodes = self._kg_retriever.retrieve(query_bundle)\n",
    "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
    "\n",
    "        unique_nodes = {n.node_id: n for n in kg_nodes}\n",
    "        unique_nodes.update({n.node_id: n for n in vector_nodes})\n",
    "        return list(unique_nodes.values())\n",
    "custom_retriever = CustomRetriever(kg_retriever, vector_retriever)\n",
    "\n",
    "nodes = custom_retriever.retrieve(\n",
    "    \"Gib mir die ganze Reihe für den Zylinderrollenlager DIN5412 mit d=55\"\n",
    ")\n",
    "\n",
    "print(len(nodes))\n",
    "for idx, node in enumerate(nodes):\n",
    "    print(f\">> IDX: {idx}, {node.get_content()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
